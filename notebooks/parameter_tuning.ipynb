{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msfm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpose_estimation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimate_poses_incremental, force_loop_closure\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msfm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtriangulation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m triangulate_all_points, merge_triangulated_points\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msfm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbundle_adjustment\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_global_ba\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdense_reconstruction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmvs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m process_mvs\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdense_reconstruction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpoint_cloud\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m process_dense_reconstruction, create_surface_mesh, save_mesh\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eier\\master_school_work\\computer_vision\\2Dto3D-Net\\notebooks\\..\\src\\sfm\\bundle_adjustment.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lil_matrix\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m least_squares\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eier\\master_school_work\\computer_vision\\2Dto3D-Net\\venv\\Lib\\site-packages\\scipy\\sparse\\__init__.py:315\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_index_dtype, safely_cast_index_arrays\n\u001b[32m    314\u001b[39m \u001b[38;5;66;03m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csgraph\n\u001b[32m    317\u001b[39m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    319\u001b[39m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[32m    320\u001b[39m     lil, sparsetools, sputils\n\u001b[32m    321\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eier\\master_school_work\\computer_vision\\2Dto3D-Net\\venv\\Lib\\site-packages\\scipy\\sparse\\csgraph\\__init__.py:187\u001b[39m\n\u001b[32m    158\u001b[39m __docformat__ = \u001b[33m\"\u001b[39m\u001b[33mrestructuredtext en\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mconnected_components\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    161\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mlaplacian\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    162\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mshortest_path\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    184\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mcsgraph_to_masked\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    185\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mNegativeCycleError\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_laplacian\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m laplacian\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_shortest_path\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    189\u001b[39m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson, yen,\n\u001b[32m    190\u001b[39m     NegativeCycleError\n\u001b[32m    191\u001b[39m )\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_traversal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    193\u001b[39m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[32m    194\u001b[39m     depth_first_tree, connected_components\n\u001b[32m    195\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eier\\master_school_work\\computer_vision\\2Dto3D-Net\\venv\\Lib\\site-packages\\scipy\\sparse\\csgraph\\_laplacian.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_pydata_sparse_to_scipy, is_pydata_spmatrix\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Graph laplacian\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eier\\master_school_work\\computer_vision\\2Dto3D-Net\\venv\\Lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py:134\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dsolve\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_eigen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_matfuncs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_onenormest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eier\\master_school_work\\computer_vision\\2Dto3D-Net\\venv\\Lib\\site-packages\\scipy\\sparse\\linalg\\_eigen\\__init__.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01marpack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlobpcg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_svds\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m svds\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m arpack\n\u001b[32m     15\u001b[39m __all__ = [\n\u001b[32m     16\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mArpackError\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mArpackNoConvergence\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m'\u001b[39m\u001b[33meigs\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33meigsh\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlobpcg\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msvds\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     18\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eier\\master_school_work\\computer_vision\\2Dto3D-Net\\venv\\Lib\\site-packages\\scipy\\sparse\\linalg\\_eigen\\_svds.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearOperator, aslinearoperator\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_eigen\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlobpcg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lobpcg  \u001b[38;5;66;03m# type: ignore[no-redef]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_svdp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _svdp\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m svd\n\u001b[32m     13\u001b[39m arpack_int = _arpack.timing.nbx.dtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eier\\master_school_work\\computer_vision\\2Dto3D-Net\\venv\\Lib\\site-packages\\scipy\\sparse\\linalg\\_svdp.py:26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_propack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _dpropack  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_propack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _cpropack  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_propack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _zpropack  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m     29\u001b[39m _lansvd_dict = {\n\u001b[32m     30\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m: _spropack.slansvd,\n\u001b[32m     31\u001b[39m     \u001b[33m'\u001b[39m\u001b[33md\u001b[39m\u001b[33m'\u001b[39m: _dpropack.dlansvd,\n\u001b[32m     32\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mF\u001b[39m\u001b[33m'\u001b[39m: _cpropack.clansvd,\n\u001b[32m     33\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mD\u001b[39m\u001b[33m'\u001b[39m: _zpropack.zlansvd,\n\u001b[32m     34\u001b[39m }\n\u001b[32m     37\u001b[39m _lansvd_irl_dict = {\n\u001b[32m     38\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m: _spropack.slansvd_irl,\n\u001b[32m     39\u001b[39m     \u001b[33m'\u001b[39m\u001b[33md\u001b[39m\u001b[33m'\u001b[39m: _dpropack.dlansvd_irl,\n\u001b[32m     40\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mF\u001b[39m\u001b[33m'\u001b[39m: _cpropack.clansvd_irl,\n\u001b[32m     41\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mD\u001b[39m\u001b[33m'\u001b[39m: _zpropack.zlansvd_irl,\n\u001b[32m     42\u001b[39m }\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import yaml\n",
    "import open3d as o3d\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "cv2.setRNGSeed(42)\n",
    "\n",
    "# Add the project directory to the Python path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.preprocessing.image_loader import load_image_sequence, resize_images\n",
    "from src.preprocessing.image_preprocessing import enhance_contrast\n",
    "from src.feature_extraction.sift_extractor import extract_features_from_image_set\n",
    "from src.feature_extraction.orb_extractor import extract_distributed_orb_features, extract_orb_features\n",
    "from src.feature_extraction.feature_matcher import match_image_pairs, geometric_verification\n",
    "from src.sfm.camera_calibration import estimate_camera_matrix\n",
    "from src.sfm.pose_estimation import estimate_poses_incremental, force_loop_closure\n",
    "from src.sfm.triangulation import triangulate_all_points, merge_triangulated_points\n",
    "from src.sfm.bundle_adjustment import run_global_ba\n",
    "from src.dense_reconstruction.mvs import process_mvs\n",
    "from src.dense_reconstruction.point_cloud import process_dense_reconstruction, create_surface_mesh, save_mesh\n",
    "from src.surface_reconstruction.mesh_generation import process_point_cloud_to_mesh, clean_mesh\n",
    "from src.surface_reconstruction.texture_mapping import create_textured_mesh_from_point_cloud\n",
    "\n",
    "from src.visualization.plot_matches import plot_matches, plot_feature_matching_analysis\n",
    "from src.visualization.point_cloud_visualizer import plot_interactive_point_cloud, create_point_cloud_animation\n",
    "from src.visualization.camera_visualizer import plot_interactive_camera_poses\n",
    "from src.visualization.mesh_visualizer import visualize_mesh_o3d, plot_interactive_mesh\n",
    "\n",
    "# Set up matplotlib for inline display\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "# Base configuration (from paste-2.txt)\n",
    "base_config = {\n",
    "    'preprocessing': {\n",
    "        'resize_max_dimension': 1000,\n",
    "        'enhance_contrast': True\n",
    "    },\n",
    "    'features': {\n",
    "        'method': 'sift',\n",
    "        'max_features': 50000,\n",
    "        'use_multiscale': True,\n",
    "        'use_dense': True,\n",
    "        'dense_step': 5,\n",
    "        'contrast_threshold': 0.01,\n",
    "        'edge_threshold': 8\n",
    "    },\n",
    "    'matching': {\n",
    "        'ratio_threshold': 0.7,\n",
    "        'geometric_verification': True,\n",
    "        'min_matches': 16,\n",
    "        'verification_method': 'fundamental',\n",
    "        'ransac_threshold': 2.0,\n",
    "        'cross_check': True,\n",
    "        'max_epipolar_error': 1.0,\n",
    "        'confidence': 0.999\n",
    "    },\n",
    "    'calibration': {\n",
    "        'focal_length_factor': 1.3,\n",
    "        'principal_point': 'center',\n",
    "        'refine_intrinsics': True\n",
    "    },\n",
    "    'sfm': {\n",
    "        'incremental': True,\n",
    "        'refine_poses': True,\n",
    "        'min_triangulation_angle_deg': 3.0,\n",
    "        'reprojection_error_threshold': 2.0,\n",
    "        'bundle_adjustment_max_iterations': 100\n",
    "    },\n",
    "    'mvs': {\n",
    "        'min_disparity': 0,\n",
    "        'num_disparities': 128,\n",
    "        'block_size': 7,\n",
    "        'filter_depths': True,\n",
    "        'consistency_threshold': 0.01,\n",
    "        'num_source_views': 5\n",
    "    },\n",
    "    'point_cloud': {\n",
    "        'voxel_size': 0.02,\n",
    "        'nb_neighbors': 30,\n",
    "        'std_ratio': 1.5,\n",
    "        'confidence_threshold': 0.8\n",
    "    },\n",
    "    'surface': {\n",
    "        'method': 'poisson',\n",
    "        'depth': 10,\n",
    "        'cleanup': True,\n",
    "        'trim': 7.0\n",
    "    },\n",
    "    'visualization': {\n",
    "        'point_size': 2,\n",
    "        'camera_size': 6,\n",
    "        'point_color_method': 'rgb'\n",
    "    }\n",
    "}\n",
    "\n",
    "hyperparameter_grid = {\n",
    "    'features': {\n",
    "        'method': ['sift'],  \n",
    "        'max_features': [50000, 100000],\n",
    "        'contrast_threshold': [0.01, 0.005, 0.001]\n",
    "    },\n",
    "    'matching': {\n",
    "        'ratio_threshold': [0.65, 0.75, 0.85],\n",
    "        'min_matches': [10, 15, 20, 25]\n",
    "    },\n",
    "    'calibration': {\n",
    "        'focal_length_factor': [1.1, 1.2, 1.3]\n",
    "    },\n",
    "}\n",
    "\n",
    "# Function to generate all possible hyperparameter combinations\n",
    "def generate_hyperparameter_combinations(grid):\n",
    "    # Create lists of parameter combinations for each section\n",
    "    section_combinations = {}\n",
    "    for section, params in grid.items():\n",
    "        section_keys = list(params.keys())\n",
    "        section_values = list(itertools.product(*[params[key] for key in section_keys]))\n",
    "        section_combinations[section] = [dict(zip(section_keys, values)) for values in section_values]\n",
    "    \n",
    "            # We're only using SIFT, so no special handling needed for ORB\n",
    "    feature_combinations = []\n",
    "    for combo in section_combinations['features']:\n",
    "        feature_combinations.append(combo)\n",
    "    section_combinations['features'] = feature_combinations\n",
    "    \n",
    "    # Generate all combinations across all sections\n",
    "    all_combinations = []\n",
    "    \n",
    "    # Get all combinations of section combinations\n",
    "    features_combos = section_combinations['features']\n",
    "    matching_combos = section_combinations['matching']\n",
    "    calibration_combos = section_combinations['calibration']\n",
    "    sfm_combos = section_combinations['sfm']\n",
    "    \n",
    "    # Product of all section combinations\n",
    "    for f_combo in features_combos:\n",
    "        for m_combo in matching_combos:\n",
    "            for c_combo in calibration_combos:\n",
    "                for s_combo in sfm_combos:\n",
    "                    # Create a copy of the base configuration\n",
    "                    config = copy.deepcopy(base_config)\n",
    "                    \n",
    "                    # Update with the current combination\n",
    "                    config['features'].update(f_combo)\n",
    "                    config['matching'].update(m_combo)\n",
    "                    config['calibration'].update(c_combo)\n",
    "                    config['sfm'].update(s_combo)\n",
    "                    \n",
    "                    all_combinations.append(config)\n",
    "    \n",
    "    return all_combinations\n",
    "\n",
    "# Main function to run reconstruction with a specific configuration\n",
    "def run_reconstruction(config, dataset_path_black, dataset_path_original, output_dir, config_id):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Running configuration {config_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Create a specific output directory for this configuration\n",
    "    config_output_dir = os.path.join(output_dir, f\"config_{config_id}\")\n",
    "    os.makedirs(config_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save configuration to output directory\n",
    "    with open(os.path.join(config_output_dir, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    # Create a parameter summary string for plot titles\n",
    "    param_summary = (\n",
    "        f\"Features: {config['features']['max_features']}, \"\n",
    "        f\"Ratio: {config['matching']['ratio_threshold']}, \"\n",
    "        f\"MinMatches: {config['matching']['min_matches']}, \"\n",
    "        f\"Focal: {config['calibration']['focal_length_factor']}, \"\n",
    "        f\"TriangAngle: {config['sfm']['min_triangulation_angle_deg']}, \"\n",
    "        f\"ReprojErr: {config['sfm']['reprojection_error_threshold']}\"\n",
    "    )\n",
    "    \n",
    "    # Create a shorter parameter summary for filenames\n",
    "    param_filename = (\n",
    "        f\"F{config['features']['max_features']}_\"\n",
    "        f\"R{config['matching']['ratio_threshold']}_\"\n",
    "        f\"M{config['matching']['min_matches']}_\"\n",
    "        f\"FL{config['calibration']['focal_length_factor']}_\"\n",
    "        f\"TA{config['sfm']['min_triangulation_angle_deg']}_\"\n",
    "        f\"RE{config['sfm']['reprojection_error_threshold']}\"\n",
    "    )\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a results dictionary to track metrics\n",
    "    results = {\n",
    "        'config_id': config_id,\n",
    "        'parameters': param_summary,\n",
    "        'start_time': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        'metrics': {}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Load and preprocess images\n",
    "        print(\"Loading black background images...\")\n",
    "        black_images = load_image_sequence(dataset_path_black, pattern=\"viff.*.png\")\n",
    "        print(f\"Loaded {len(black_images)} black background images.\")\n",
    "        \n",
    "        print(\"Loading original background images...\")\n",
    "        original_images = load_image_sequence(dataset_path_original, pattern=\"viff.*.png\")\n",
    "        print(f\"Loaded {len(original_images)} original background images.\")\n",
    "        \n",
    "        # Make sure image lists are the same length and in the same order\n",
    "        if len(black_images) != len(original_images):\n",
    "            print(\"Warning: Different number of images in the two datasets\")\n",
    "            blackfilenames = [filename for _, filename in black_images]\n",
    "            originalfilenames = [filename for _, filename in original_images]\n",
    "            common_filenames = set(blackfilenames).intersection(set(originalfilenames))\n",
    "            \n",
    "            black_images = [(img, filename) for img, filename in black_images if filename in common_filenames]\n",
    "            original_images = [(img, filename) for img, filename in original_images if filename in common_filenames]\n",
    "            \n",
    "            print(f\"Using {len(black_images)} images that exist in both datasets\")\n",
    "        \n",
    "        # Initialize points_3d to empty list in case triangulation fails\n",
    "        points_3d = []\n",
    "        point_observations = []\n",
    "        \n",
    "        # Resize images\n",
    "        max_dim = config['preprocessing']['resize_max_dimension']\n",
    "        black_images = resize_images(black_images, max_dimension=max_dim)\n",
    "        original_images = resize_images(original_images, max_dimension=max_dim)\n",
    "        \n",
    "        # Enhance contrast if specified\n",
    "        if config['preprocessing']['enhance_contrast']:\n",
    "            black_images = enhance_contrast(black_images)\n",
    "            original_images = enhance_contrast(original_images)\n",
    "        \n",
    "        # Step 2: Extract features\n",
    "        print(\"\\nExtracting features...\")\n",
    "        feature_method = config['features']['method']\n",
    "        max_features = config['features']['max_features']\n",
    "        \n",
    "        # Extract features using the exact pattern from the original code\n",
    "        feature_method = config['features']['method']\n",
    "        max_features = config['features']['max_features']\n",
    "\n",
    "        contrast_threshold = config['features']['contrast_threshold']\n",
    "        \n",
    "        # Extract features exactly as in the original code\n",
    "        if feature_method.lower() == 'sift':\n",
    "            print(f\"Using SIFT extraction with target of {max_features} features per image\")\n",
    "            features_dict = extract_features_from_image_set(black_images, method=feature_method, n_features=max_features, contrast_threshold=contrast_threshold)\n",
    "        else:\n",
    "            # For other methods, use standard extraction\n",
    "            features_dict = extract_features_from_image_set(black_images, method=feature_method, n_features=max_features, contrast_threshold=contrast_threshold)\n",
    "        \n",
    "        # Count features\n",
    "        total_features = sum(len(keypoints) for keypoints, _ in features_dict.values())\n",
    "        avg_features = total_features / len(features_dict)\n",
    "        print(f\"Total features extracted: {total_features} (avg {avg_features:.0f} per image)\")\n",
    "        \n",
    "        results['metrics']['total_features'] = total_features\n",
    "        results['metrics']['avg_features_per_image'] = avg_features\n",
    "        \n",
    "        # Step 3: Create image pairs and match features\n",
    "        filenames = sorted([filename for _, filename in black_images], \n",
    "                          key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "        \n",
    "        # Number of images\n",
    "        n = len(filenames)\n",
    "        \n",
    "        # Create image pairs for matching with a comprehensive circular strategy\n",
    "        image_pairs = []\n",
    "        \n",
    "        # 1. Keep sequential pairs as your foundation\n",
    "        for i in range(n-1):\n",
    "            image_pairs.append((filenames[i], filenames[i+1]))\n",
    "        image_pairs.append((filenames[-1], filenames[0]))  # Close the loop\n",
    "        \n",
    "        # Remove duplicates while preserving order\n",
    "        seen = set()\n",
    "        image_pairs = [x for x in image_pairs if not (x in seen or seen.add(x))]\n",
    "        \n",
    "        print(f\"Created {len(image_pairs)} image pairs for matching\")\n",
    "        \n",
    "        # Match features exactly as in the original code\n",
    "        matches_dict = match_image_pairs(\n",
    "            features_dict, \n",
    "            image_pairs, \n",
    "            ratio_threshold=config['matching']['ratio_threshold'],\n",
    "            geometric_verify=config['matching']['geometric_verification'],\n",
    "            min_matches=config['matching']['min_matches']\n",
    "        )\n",
    "        \n",
    "        num_matched_pairs = len(matches_dict)\n",
    "        print(f\"Successfully matched {num_matched_pairs} image pairs.\")\n",
    "        results['metrics']['matched_image_pairs'] = num_matched_pairs\n",
    "        \n",
    "        # Step 4: Estimate camera intrinsics\n",
    "        sample_img, _ = black_images[0]\n",
    "        image_shape = sample_img.shape\n",
    "        focal_length_factor = config['calibration']['focal_length_factor']\n",
    "        focal_length = focal_length_factor * max(image_shape[0], image_shape[1])\n",
    "        K = estimate_camera_matrix(image_shape, focal_length)\n",
    "        \n",
    "        # Step 5: Estimate camera poses\n",
    "        camera_poses = estimate_poses_incremental(\n",
    "            matches_dict, \n",
    "            K, \n",
    "            min_matches=config['matching']['min_matches']\n",
    "        )\n",
    "        \n",
    "        num_camera_poses = len(camera_poses)\n",
    "        print(f\"Estimated poses for {num_camera_poses} cameras.\")\n",
    "        results['metrics']['camera_poses'] = num_camera_poses\n",
    "        \n",
    "        # Visualize and save camera poses plot\n",
    "        if num_camera_poses > 0:\n",
    "            # Save camera poses as static plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            \n",
    "            # Extract camera centers for plotting\n",
    "            camera_centers = {}\n",
    "            for name, (R, t) in camera_poses.items():\n",
    "                center = -R.T @ t\n",
    "                camera_centers[name] = center\n",
    "            \n",
    "            # Plot camera centers\n",
    "            centers = np.array(list(camera_centers.values()))\n",
    "            plt.scatter(centers[:, 0], centers[:, 1], c='r', marker='o', s=50)\n",
    "            \n",
    "            plt.title(f\"Camera Poses (Top View)\\n{param_summary}\")\n",
    "            plt.xlabel('X')\n",
    "            plt.ylabel('Y')\n",
    "            plt.grid(True)\n",
    "            \n",
    "            camera_plot_path = os.path.join(config_output_dir, f\"camera_poses_{param_filename}.png\")\n",
    "            plt.savefig(camera_plot_path, dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            results['metrics']['camera_plot_path'] = camera_plot_path\n",
    "            \n",
    "            # Also save the 3D point cloud if available\n",
    "            if points_3d and len(points_3d) > 0:\n",
    "                # Create a static plot of the point cloud (top view)\n",
    "                plt.figure(figsize=(12, 10))\n",
    "                points_array = np.array(points_3d)\n",
    "                plt.scatter(points_array[:, 0], points_array[:, 1], s=1, alpha=0.5, c='blue')\n",
    "                plt.scatter(centers[:, 0], centers[:, 1], c='r', marker='o', s=50)\n",
    "                plt.title(f\"Sparse 3D Reconstruction: {len(points_array)} points (Top View)\\n{param_summary}\")\n",
    "                plt.xlabel('X')\n",
    "                plt.ylabel('Y')\n",
    "                plt.grid(True)\n",
    "                \n",
    "                point_cloud_path = os.path.join(config_output_dir, f\"sparse_cloud_{param_filename}.png\")\n",
    "                plt.savefig(point_cloud_path, dpi=300)\n",
    "                plt.close()\n",
    "                \n",
    "                results['metrics']['point_cloud_plot_path'] = point_cloud_path\n",
    "        \n",
    "        # Step 6: Triangulate 3D points\n",
    "        points_3d, point_observations = triangulate_all_points(\n",
    "            camera_poses, \n",
    "            matches_dict, \n",
    "            K,\n",
    "            min_angle_deg=config['sfm']['min_triangulation_angle_deg'],\n",
    "            max_reproj_error=config['sfm']['max_reprojection_error']\n",
    "        )\n",
    "        \n",
    "        num_triangulated_points = len(points_3d)\n",
    "        print(f\"Triangulated {num_triangulated_points} 3D points.\")\n",
    "        results['metrics']['triangulated_points'] = num_triangulated_points\n",
    "        \n",
    "        # Merge close points\n",
    "        merged_points, merged_observations = merge_triangulated_points(\n",
    "            points_3d, \n",
    "            point_observations, \n",
    "            threshold=config['sfm']['merge_threshold']\n",
    "        )\n",
    "        \n",
    "        num_merged_points = len(merged_points)\n",
    "        print(f\"After merging: {num_merged_points} 3D points.\")\n",
    "        results['metrics']['merged_points'] = num_merged_points\n",
    "        \n",
    "        # Step 7: Bundle adjustment\n",
    "        if config['sfm']['refine_poses'] and num_merged_points > 0:\n",
    "            print(\"\\nRunning bundle adjustment...\")\n",
    "            refined_poses, refined_points, _ = run_global_ba(\n",
    "                camera_poses, \n",
    "                matches_dict, \n",
    "                K, \n",
    "                iterations=20\n",
    "            )\n",
    "            points_3d = refined_points\n",
    "            \n",
    "            num_refined_points = len(refined_points)\n",
    "            print(f\"Bundle adjustment complete with {num_refined_points} refined points.\")\n",
    "            results['metrics']['refined_points'] = num_refined_points\n",
    "        \n",
    "        # Step 8: Visualize and save sparse point cloud\n",
    "        if len(points_3d) > 0:\n",
    "            points_array = np.array(points_3d)\n",
    "            \n",
    "            # Assign random colors for visualization\n",
    "            np.random.seed(42)  # For reproducibility\n",
    "            colors = np.random.rand(len(points_array), 3)\n",
    "            \n",
    "            # Visualize sparse point cloud\n",
    "            if len(points_3d) > 0:\n",
    "                points_array = np.array(points_3d)\n",
    "                \n",
    "                # Assign random colors for visualization\n",
    "                np.random.seed(42)  # For reproducibility\n",
    "                colors = np.random.rand(len(points_array), 3)\n",
    "                \n",
    "                # Save sparse point cloud as PLY\n",
    "                sparse_cloud_file = os.path.join(config_output_dir, f\"sparse_cloud_{param_filename}.ply\")\n",
    "                pcd = o3d.geometry.PointCloud()\n",
    "                pcd.points = o3d.utility.Vector3dVector(points_array)\n",
    "                pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "                o3d.io.write_point_cloud(sparse_cloud_file, pcd)\n",
    "                print(f\"Saved sparse point cloud to {sparse_cloud_file}\")\n",
    "                \n",
    "                results['metrics']['point_cloud_file'] = sparse_cloud_file\n",
    "        \n",
    "        # Record end time and duration\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        results['duration_seconds'] = duration\n",
    "        results['end_time'] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        print(f\"\\nConfiguration {config_id} completed in {duration:.2f} seconds\")\n",
    "        print(f\"Points triangulated: {num_triangulated_points}\")\n",
    "        \n",
    "        # Calculate a simple quality score (could be refined based on your specific needs)\n",
    "        quality_score = num_merged_points * (num_camera_poses / len(black_images))\n",
    "        results['quality_score'] = quality_score\n",
    "        print(f\"Quality score: {quality_score:.2f}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error in configuration {config_id}: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        results['error'] = error_msg\n",
    "        return results\n",
    "\n",
    "# Main execution function\n",
    "def run_hyperparameter_sweep():\n",
    "    # Define paths to datasets\n",
    "    dataset_path_black = '../data/dinosaur_cropped_black/'  # Black background\n",
    "    dataset_path_original = '../data/dinosaur_cropped/'     # Original background\n",
    "    \n",
    "    # Create main output directory\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = f\"../data/results/hyperparameter_sweep_{timestamp}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate all hyperparameter combinations\n",
    "    all_configs = generate_hyperparameter_combinations(hyperparameter_grid)\n",
    "    print(f\"Generated {len(all_configs)} configurations to test\")\n",
    "    \n",
    "    # Save all configurations to a single file for reference\n",
    "    with open(os.path.join(output_dir, 'all_configurations.json'), 'w') as f:\n",
    "        json.dump(all_configs, f, indent=4)\n",
    "    \n",
    "    # Create a results list to track performance of each configuration\n",
    "    all_results = []\n",
    "    \n",
    "    # Track the best configuration by number of triangulated points\n",
    "    best_config = None\n",
    "    best_score = 0\n",
    "    \n",
    "    # Run each configuration\n",
    "    for i, config in enumerate(tqdm(all_configs, desc=\"Testing configurations\")):\n",
    "        print(f\"\\nConfiguration {i+1}/{len(all_configs)}\")\n",
    "        \n",
    "        # Run reconstruction with this configuration\n",
    "        results = run_reconstruction(\n",
    "            config, \n",
    "            dataset_path_black, \n",
    "            dataset_path_original, \n",
    "            output_dir, \n",
    "            i+1\n",
    "        )\n",
    "        \n",
    "        # Save the results\n",
    "        all_results.append(results)\n",
    "        \n",
    "        # Update the best configuration if applicable\n",
    "        if 'quality_score' in results and results['quality_score'] > best_score:\n",
    "            best_score = results['quality_score']\n",
    "            best_config = i+1\n",
    "            print(f\"New best configuration: {i+1} with score {best_score:.2f}\")\n",
    "        \n",
    "        # Save the current results to disk after each configuration\n",
    "        with open(os.path.join(output_dir, 'results_summary.json'), 'w') as f:\n",
    "            json.dump({\n",
    "                'total_configs': len(all_configs),\n",
    "                'configs_tested': i+1,\n",
    "                'best_config': best_config,\n",
    "                'best_score': best_score,\n",
    "                'results': all_results\n",
    "            }, f, indent=4)\n",
    "        \n",
    "        # Create a simple results table\n",
    "        results_df = {}\n",
    "        for res in all_results:\n",
    "            config_id = res.get('config_id', 'unknown')\n",
    "            results_df[config_id] = {\n",
    "                'triangulated_points': res.get('metrics', {}).get('triangulated_points', 0),\n",
    "                'merged_points': res.get('metrics', {}).get('merged_points', 0),\n",
    "                'camera_poses': res.get('metrics', {}).get('camera_poses', 0),\n",
    "                'quality_score': res.get('quality_score', 0),\n",
    "                'parameters': res.get('parameters', '')\n",
    "            }\n",
    "        \n",
    "        # Convert to DataFrame and save as CSV\n",
    "        import pandas as pd\n",
    "        pd_results = pd.DataFrame.from_dict(results_df, orient='index')\n",
    "        pd_results.sort_values('quality_score', ascending=False, inplace=True)\n",
    "        pd_results.to_csv(os.path.join(output_dir, 'results_table.csv'))\n",
    "        \n",
    "        # Print the current top 5 configurations\n",
    "        print(\"\\nCurrent Top 5 Configurations:\")\n",
    "        print(pd_results.head(5)[['triangulated_points', 'merged_points', 'camera_poses', 'quality_score']])\n",
    "    \n",
    "    print(\"\\n\\nHyperparameter sweep completed!\")\n",
    "    if best_config is not None:\n",
    "        print(f\"Best configuration: {best_config} with quality score {best_score:.2f}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Run the hyperparameter sweep\n",
    "results = run_hyperparameter_sweep()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
